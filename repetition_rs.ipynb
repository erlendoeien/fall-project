{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Repetition Recommender system\n",
    "### Data preperation\n",
    "First I'll load necessary data and find which ccid's were repeated.\n",
    "I'm ignoring video_id for now since I need more exploration of it (e.g. how it is distributed).\n",
    "Though using video_id might contextualise better repetition need, depending on how it was used.\n",
    "\n",
    "Firstly the itemset will only be the videos which have been repeated.\n",
    "I will then expand the item set with every video ccid which has been watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import data_path, entities_path, relations_path, Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = Path(\"mooc_cube_x-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2video = pd.read_parquet(sample_data / \"user-video.parquet.gzip\")\n",
    "# Actual dataset\n",
    "# user2video = pd.read_json(data_path / \"user-video.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id2ccid = pd.read_csv(relations_path / \"video_id-ccid.txt\", sep=\"\\t\", names=[\"video_id\", \"ccid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_vid_exploded = user2video.explode(\"seq\")\n",
    "user_video_ccid = usr_vid_exploded.assign(video_id=usr_vid_exploded[\"seq\"].str[\"video_id\"]).merge(video_id2ccid).sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the table showing how many times a user has re-watched a given video, \n",
    "potentially across courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_video_count = user_video_ccid.value_counts([\"ccid\", \"user_id\"]).reset_index().rename(columns={0: \"num_watched\"})\n",
    "user_video_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Implicit feedback\n",
    "Testing out baseline models for repetition, only considering repeated/not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_video_reconsumed = (user_video_count[user_video_count[\"num_watched\"] > 1]\n",
    "                    .rename(columns={\"user_id\": \"user\", \"ccid\": \"item\", \"num_watched\": \"rating\"}))#.pivot(index=\"user_id\", columns=\"ccid\", values=\"num_watched\")\n",
    "user_video_reconsumed#[user_video_reconsumed.index ==\"U_10232296\"].dropna(axis=1)#.iloc[0, :]#.notna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, item_knn, user_knn, als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ii = item_knn.ItemItem(10)\n",
    "algo_uu = user_knn.UserUser(10)\n",
    "algo_als = als.ImplicitMF(50)\n",
    "# algo_als = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(aname, algo, train, test):\n",
    "    \"\"\"Generates recommendations over one partition of the dataset\"\"\"\n",
    "    fittable = util.clone(algo)\n",
    "    fittable = Recommender.adapt(fittable)\n",
    "    fittable.fit(train)\n",
    "    users = test.user.unique()\n",
    "    # now we run the recommender\n",
    "    recs = batch.recommend(fittable, users, 10)\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['algorithm'] = aname\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = []\n",
    "test_data = []\n",
    "partitioned = xf.partition_users(user_video_reconsumed, 5, xf.SampleN(1))\n",
    "for idx, (train, test) in enumerate(partitioned):\n",
    "    test_data.append(test)\n",
    "    # all_recs.append(eval('ItemItem', algo_ii, train, test))\n",
    "    # all_recs.append(eval('UserUser', algo_uu, train, test))\n",
    "    all_recs.append(eval('ImplicitALS', algo_als, train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat(test_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "results = rla.compute(all_recs, test_data)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('algorithm').ndcg.mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cde0b26d51115323414c62c0565bbd3bf0aefa7cc8f6a32af1b274f8f6d093ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('rec-sys-intro': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
